#!/usr/bin/env python3
"""
Training Pipeline Debug Tool
ì²´ê³„ì ìœ¼ë¡œ ë°ì´í„° íë¦„ê³¼ í…ì„œ ìƒíƒœë¥¼ ë¶„ì„í•˜ëŠ” ë””ë²„ê¹… ë„êµ¬
"""

import torch
import sys
import os
from pathlib import Path

# Add src to path
src_path = Path(__file__).parent / "src"
sys.path.append(str(src_path))

from data.decision_transformer_dataset import DecisionTransformerDataset
from data.quantum_circuit_dataset import DatasetManager
from rtg.core.rtg_calculator import RTGCalculator
from quantumcommon.gates import gate_registry

def debug_data_pipeline():
    """ë°ì´í„° íŒŒì´í”„ë¼ì¸ ì „ì²´ íë¦„ ë””ë²„ê¹…"""
    print("=" * 60)
    print("ğŸ” TRAINING PIPELINE DEBUG ANALYSIS")
    print("=" * 60)
    
    # 1. Gate Registry ìƒíƒœ í™•ì¸
    print("\n1ï¸âƒ£ GATE REGISTRY ANALYSIS")
    gate_vocab = gate_registry.get_gate_vocab()
    print(f"   Gate vocabulary size: {len(gate_vocab)}")
    print(f"   Gate types: {list(gate_vocab.keys())}")
    print(f"   Gate indices: {list(gate_vocab.values())}")
    
    # 2. ë°ì´í„°ì…‹ ë¡œë”© ë° ìƒ˜í”Œ ë¶„ì„
    print("\n2ï¸âƒ£ DATASET LOADING ANALYSIS")
    try:
        # Load sample data
        data_path = "dummy_quantum_dataset.json"
        if not os.path.exists(data_path):
            print(f"   âŒ Dataset file not found: {data_path}")
            return
            
        dataset_manager = DatasetManager()
        quantum_dataset = dataset_manager.merge_data([data_path])
        
        print(f"   âœ… Loaded {len(quantum_dataset)} circuit samples")
        
        # Sample circuit analysis
        if quantum_dataset:
            sample = quantum_dataset[0]
            circuit_spec = sample.circuit_spec
            print(f"   Sample circuit: {circuit_spec.circuit_id}")
            print(f"   Gates count: {len(circuit_spec.gates)}")
            print(f"   Qubits: {circuit_spec.num_qubits}")
            
            # Gate type analysis
            gate_types = [gate.name.lower() for gate in circuit_spec.gates]
            print(f"   Gate types in sample: {set(gate_types)}")
            
            # Check for unknown gates
            unknown_gates = [g for g in gate_types if g not in gate_vocab]
            if unknown_gates:
                print(f"   âš ï¸ Unknown gates found: {set(unknown_gates)}")
            else:
                print(f"   âœ… All gates are in vocabulary")
                
    except Exception as e:
        print(f"   âŒ Dataset loading failed: {e}")
        return
    
    # 3. RTG Calculator ë¶„ì„
    print("\n3ï¸âƒ£ RTG CALCULATOR ANALYSIS")
    try:
        rtg_calculator = RTGCalculator()
        target_properties = {'entanglement': 0.8, 'expressibility': 0.7}
        
        rtg_values, rewards, properties = rtg_calculator.calculate_rtg(
            circuit_spec, target_properties
        )
        
        print(f"   âœ… RTG calculation successful")
        print(f"   RTG values shape: {len(rtg_values)}")
        print(f"   RTG range: [{min(rtg_values):.3f}, {max(rtg_values):.3f}]")
        print(f"   Rewards shape: {len(rewards)}")
        print(f"   Properties: {properties}")
        
    except Exception as e:
        print(f"   âŒ RTG calculation failed: {e}")
        return
    
    # 4. DecisionTransformerDataset ë¶„ì„
    print("\n4ï¸âƒ£ DATASET EPISODE CREATION ANALYSIS")
    try:
        dt_dataset = DecisionTransformerDataset(
            quantum_dataset=quantum_dataset,
            rtg_calculator=rtg_calculator,
            max_seq_length=64,
            target_properties=target_properties,
            d_model=256
        )
        
        print(f"   âœ… Dataset created with {len(dt_dataset)} episodes")
        
        # Analyze first episode
        if len(dt_dataset) > 0:
            episode = dt_dataset[0]
            print(f"   Episode keys: {list(episode.keys())}")
            
            # Tensor shape analysis
            for key, value in episode.items():
                if isinstance(value, torch.Tensor):
                    print(f"   {key}: shape={value.shape}, dtype={value.dtype}")
                    if key == 'actions':
                        print(f"      Actions range: [{value.min().item():.3f}, {value.max().item():.3f}]")
                        # Check for out-of-bounds values
                        if value.min() < 0 or value.max() >= len(gate_vocab):
                            print(f"      âš ï¸ Actions contain out-of-bounds values!")
                            print(f"      Vocab size: {len(gate_vocab)}")
                else:
                    print(f"   {key}: {type(value)} = {value}")
                    
    except Exception as e:
        print(f"   âŒ Dataset creation failed: {e}")
        import traceback
        traceback.print_exc()
        return
    
    # 5. Embedding Pipeline ë¶„ì„
    print("\n5ï¸âƒ£ EMBEDDING PIPELINE ANALYSIS")
    try:
        from data.embedding_pipeline_refactored import EmbeddingPipeline, EmbeddingConfig
        
        embedding_config = EmbeddingConfig(
            d_model=256,
            n_gate_types=len(gate_vocab),
            n_qubits=circuit_spec.num_qubits,
            max_seq_len=64
        )
        
        embedding_pipeline = EmbeddingPipeline(embedding_config)
        result = embedding_pipeline.process_circuit(circuit_spec)
        
        print(f"   âœ… Embedding pipeline successful")
        print(f"   Result keys: {list(result.keys())}")
        
        if 'decision_transformer' in result:
            dt_result = result['decision_transformer']
            print(f"   DT result keys: {list(dt_result.keys())}")
            
            if 'input_sequence' in dt_result:
                seq = dt_result['input_sequence']
                print(f"   Input sequence shape: {seq.shape}")
                print(f"   Input sequence range: [{seq.min().item():.3f}, {seq.max().item():.3f}]")
                
    except Exception as e:
        print(f"   âŒ Embedding pipeline failed: {e}")
        import traceback
        traceback.print_exc()
    
    print("\n" + "=" * 60)
    print("ğŸ¯ DEBUGGING RECOMMENDATIONS")
    print("=" * 60)
    
    recommendations = [
        "1. ë°ì´í„° íŒŒì´í”„ë¼ì¸ í†µí•©: EmbeddingPipeline â†’ Dataset â†’ Collator ì¼ê´€ì„± í™•ë³´",
        "2. Gate vocabulary ê²€ì¦: ëª¨ë“  gateê°€ vocabì— í¬í•¨ë˜ëŠ”ì§€ í™•ì¸",
        "3. Tensor lifecycle ê´€ë¦¬: Loss computationì—ì„œ detach() ì ì ˆíˆ ì‚¬ìš©",
        "4. Action encoding í‘œì¤€í™”: Gate index, qubit positions, parameters í˜•ì‹ í†µì¼",
        "5. ë‹¨ê³„ë³„ ë””ë²„ê¹…: ê° ì»´í¬ë„ŒíŠ¸ë¥¼ ë…ë¦½ì ìœ¼ë¡œ í…ŒìŠ¤íŠ¸"
    ]
    
    for rec in recommendations:
        print(f"   â€¢ {rec}")
    
    print(f"\nğŸ’¡ ë‹¤ìŒ ëª…ë ¹ì–´ë¡œ ì´ ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰:")
    print(f"   python debug_training_pipeline.py")

if __name__ == "__main__":
    debug_data_pipeline()
