"""
Quantum Circuit Dataset Module
ê°„ë‹¨í•˜ê³  í™•ì¥ì„± ë†’ì€ ì–‘ìíšŒë¡œ ë°ì´í„°ì…‹ ì²˜ë¦¬
"""

import json
import os
import torch
from torch.utils.data import Dataset, DataLoader
from typing import Dict, List, Tuple, Any, Optional
from dataclasses import dataclass
from pathlib import Path
import numpy as np
from sklearn.model_selection import train_test_split
import sys
import pathlib
import re
sys.path.append(str(pathlib.Path(__file__).parent.parent.parent.parent / "quantumcommon"))
from gates import gate_registry, GateType, GateOperation
# ê³µí†µ ë°ì´í„° êµ¬ì¡° ê°€ì ¸ì˜¤ê¸°
from .quantum_data_structures import CircuitData, CircuitSpec, MeasurementResult, PropertyNormalizer, extract_depth_from_circuit_id

# ìˆœí™˜ ì°¸ì¡° ë°©ì§€ë¥¼ ìœ„í•´ ì§€ì—­ ì„í¬íŠ¸ ì‚¬ìš©


class QuantumCircuitDataset(Dataset):
    """ì–‘ì íšŒë¡œ ë°ì´í„°ì…‹"""
    
    def __init__(self, circuit_data: List[CircuitData]):
        # ì§€ì—° ì„í¬íŠ¸ ì‚¬ìš© - ìˆœí™˜ ì°¸ì¡° ë°©ì§€
        from .base_quantum_dataset import PropertyPredictionDataset
        self._dataset = PropertyPredictionDataset(circuit_data)
        self.circuit_data = circuit_data
    
    def __getitem__(self, idx: int) -> CircuitData:
        """ê¸°ì¡´ í˜¸í™˜ì„±ì„ ìœ„í•´ CircuitData ì§ì ‘ ë°˜í™˜"""
        return self.circuit_data[idx]
        
    def __len__(self) -> int:
        return len(self.circuit_data)


class DatasetManager:
    """ë°ì´í„°ì…‹ ê´€ë¦¬ì - ë¡œë”©, ë¶„í• , ë³€í™˜ ë‹´ë‹¹"""
    
    def __init__(self, unified_data_path: Optional[str] = None, results_path: Optional[str] = None, circuits_path: Optional[str] = None, merged_results_path: Optional[str] = None):
        """ë°ì´í„°ì…‹ ë§¤ë‹ˆì € ì´ˆê¸°í™”
        
        Args:
            unified_data_path: í†µí•© ë°ì´í„° íŒŒì¼ ê²½ë¡œ (merged_resultsì™€ merged_circuits ëª¨ë‘ í¬í•¨)
            results_path: ì¸¡ì • ê²°ê³¼ JSON íŒŒì¼ ê²½ë¡œ (ë ˆê±°ì‹œ ì§€ì›)
            circuits_path: íšŒë¡œ ìŠ¤í™ JSON íŒŒì¼ ê²½ë¡œ (ë ˆê±°ì‹œ ì§€ì›)
            merged_results_path: ë³‘í•©ëœ ê²°ê³¼ JSON íŒŒì¼ ê²½ë¡œ (ë ˆê±°ì‹œ ì§€ì›)
        """
        self.unified_data_path = Path(unified_data_path) if unified_data_path else None
        self.results_path = Path(results_path) if results_path else None
        self.circuits_path = Path(circuits_path) if circuits_path else None
        self.merged_results_path = Path(merged_results_path) if merged_results_path else None
        
        self.raw_results_data = None
        self.raw_circuits_data = None
        self.circuit_data = None
        
        # ì •ê·œí™” ìœ í‹¸ë¦¬í‹° ì´ˆê¸°í™”
        self.property_normalizer = PropertyNormalizer()
    
    def load_results_data(self) -> Dict[str, Any]:
        """ì¸¡ì • ê²°ê³¼ JSON ë°ì´í„° ë¡œë”©"""
        if self.unified_data_path and self.unified_data_path.exists():
            # í†µí•© ë°ì´í„° íŒŒì¼ì—ì„œ ë¡œë”©
            with open(self.unified_data_path, 'r', encoding='utf-8') as f:
                data = json.load(f)
                self.raw_results_data = data
                return data
        elif self.merged_results_path and self.merged_results_path.exists():
            # ë³‘í•©ëœ ê²°ê³¼ íŒŒì¼ì—ì„œ ë¡œë”© (ë ˆê±°ì‹œ ì§€ì›)
            with open(self.merged_results_path, 'r', encoding='utf-8') as f:
                data = json.load(f)
                self.raw_results_data = data
                return data
        elif self.results_path and self.results_path.exists():
            # ê°œë³„ ê²°ê³¼ íŒŒì¼ì—ì„œ ë¡œë”© (ë ˆê±°ì‹œ ì§€ì›)
            with open(self.results_path, 'r', encoding='utf-8') as f:
                self.raw_results_data = json.load(f)
                return self.raw_results_data
        else:
            raise FileNotFoundError("ê²°ê³¼ ë°ì´í„° íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    
    def load_circuits_data(self) -> Dict[str, Any]:
        """íšŒë¡œ ìŠ¤í™ JSON ë°ì´í„° ë¡œë”©"""
        if self.unified_data_path and self.unified_data_path.exists():
            # í†µí•© ë°ì´í„° íŒŒì¼ì—ì„œ ë¡œë”© (ì´ë¯¸ load_results_dataì—ì„œ ë¡œë”©ëœ ê²½ìš° ì¬ì‚¬ìš©)
            if self.raw_results_data is None:
                with open(self.unified_data_path, 'r', encoding='utf-8') as f:
                    self.raw_results_data = json.load(f)
            self.raw_circuits_data = self.raw_results_data  # ê°™ì€ íŒŒì¼ì—ì„œ circuits ì •ë³´ ì¶”ì¶œ
            return self.raw_circuits_data
        elif self.circuits_path and self.circuits_path.exists():
            # ê°œë³„ íšŒë¡œ íŒŒì¼ì—ì„œ ë¡œë”© (ë ˆê±°ì‹œ ì§€ì›)
            with open(self.circuits_path, 'r', encoding='utf-8') as f:
                self.raw_circuits_data = json.load(f)
                return self.raw_circuits_data
        else:
            raise FileNotFoundError("íšŒë¡œ ìŠ¤í™ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    
    def load_measurement_results(self, file_path: str) -> Dict[str, MeasurementResult]:
        """ì¸¡ì • ê²°ê³¼ íŒŒì¼ ë¡œë”© - merged_resultsì™€ IBM results í˜•ì‹ ëª¨ë‘ ì§€ì›"""
        with open(file_path, 'r', encoding='utf-8') as f:
            data = json.load(f)
        
        # ë¨¼ì € ì „ì²´ ë°ì´í„°ì—ì„œ ì–½í˜ë„ min/max ë²”ìœ„ë¥¼ ê³„ì‚°í•˜ê¸° ìœ„í•´ raw ë°ì´í„° ì¶”ì¶œ
        all_results = []
        if 'merged_results' in data:
            all_results = data['merged_results']
        elif 'results' in data:
            all_results = data['results']
        elif isinstance(data, list):
            all_results = data
        else:
            raise ValueError(f"Unsupported JSON format in {file_path}. Expected 'merged_results', 'results', or list format.")
        
        # ì–½í˜ë„ Robust ì •ê·œí™”ë¥¼ ìœ„í•´ normalizer í•™ìŠµ (scalability ë°ì´í„°ë§Œ ì‚¬ìš©)
        print("Fitting entanglement robust normalizer on scalability test data...")
        scalability_results = [r for r in all_results if 'scalability' in r.get('circuit_id', '')]
        print(f"Found {len(scalability_results)} scalability test circuits out of {len(all_results)} total circuits")
        
        if scalability_results:
            self.property_normalizer.fit(scalability_results)
            print("Entanglement robust normalizer fitted successfully on scalability data!")
        else:
            print("âš ï¸ No scalability test data found, using all data for normalization")
            self.property_normalizer.fit(all_results)
        
        results = {}
        
        # merged_results í˜•ì‹ ì²˜ë¦¬ (ì‹œë®¬ë ˆì´í„° í˜•ì‹)
        if 'merged_results' in data:
            for result in data['merged_results']:
                # timestamp ì œê±°í•˜ê³  ì–½í˜ë„ ì •ê·œí™”
                result_data = {k: v for k, v in result.items() if k != 'timestamp'}
                # ì–½í˜ë„ Robust ì •ê·œí™” ì ìš©
                if 'entanglement' in result_data:
                    result_data['entanglement'] = self.property_normalizer.normalize_entanglement(result_data['entanglement'])
                measurement_result = MeasurementResult(**result_data)
                results[measurement_result.circuit_id] = measurement_result
        
        # IBM ì‹¤í—˜ ê²°ê³¼ í˜•ì‹ ì²˜ë¦¬
        elif 'results' in data:
            for result in data['results']:
                # timestamp ì œê±°í•˜ê³  ì–½í˜ë„ ì •ê·œí™”
                result_data = {k: v for k, v in result.items() if k != 'timestamp'}
                # ì–½í˜ë„ Robust ì •ê·œí™” ì ìš©
                if 'entanglement' in result_data:
                    result_data['entanglement'] = self.property_normalizer.normalize_entanglement(result_data['entanglement'])
                measurement_result = MeasurementResult(**result_data)
                results[measurement_result.circuit_id] = measurement_result
        
        # ë‹¨ì¼ ê²°ê³¼ í˜•ì‹ ì²˜ë¦¬ (ê¸°ì¡´ í˜¸í™˜ì„±)
        elif isinstance(data, list):
            for result in data:
                # timestamp ì œê±°í•˜ê³  ì–½í˜ë„ ì •ê·œí™”
                result_data = {k: v for k, v in result.items() if k != 'timestamp'}
                # ì–½í˜ë„ Robust ì •ê·œí™” ì ìš©
                if 'entanglement' in result_data:
                    result_data['entanglement'] = self.property_normalizer.normalize_entanglement(result_data['entanglement'])
                measurement_result = MeasurementResult(**result_data)
                results[measurement_result.circuit_id] = measurement_result
        
        return results
    
    def parse_circuit_specs(self) -> Dict[str, CircuitSpec]:
        """íšŒë¡œ ìŠ¤í™ì„ íŒŒì‹±í•˜ì—¬ circuit_idë¥¼ í‚¤ë¡œ í•˜ëŠ” ë”•ì…”ë„ˆë¦¬ ë°˜í™˜"""
        if self.raw_circuits_data is None:
            self.load_circuits_data()
        
        specs = {}
        circuits_data = self.raw_circuits_data.get('merged_circuits', {})
        
        for circuit_id, circuit_data in circuits_data.items():
            spec = CircuitSpec.from_dict(circuit_data)
            specs[circuit_id] = spec
        
        return specs
    
    def is_valid_circuit_data(self, circuit_data: CircuitData) -> bool:
        """
        íšŒë¡œ ë°ì´í„°ì˜ ìœ íš¨ì„±ì„ ê²€ì¦
        
        Args:
            circuit_data: ê²€ì¦í•  íšŒë¡œ ë°ì´í„°
            
        Returns:
            True if valid, False if invalid
        """
        result = circuit_data.measurement_result
        # 1. ê¸°ë³¸ í•„ìˆ˜ í•„ë“œ ê²€ì¦ - resultê°€ Noneì¸ ê²½ìš°ë§Œ ê±¸ëŸ¬ëƒ„
        if result is None:
            print(f"  - ìœ íš¨ì„± ê²€ì‚¬: measurement_resultê°€ Noneì„")
            return False
        
        # ì†ì„±ì´ Noneì¸ ê²½ìš° 0ìœ¼ë¡œ ì´ˆê¸°í™”í•˜ì—¬ í—ˆìš© (ë„ˆë¬´ ì—„ê²©í•œ í•„í„°ë§ ì™„í™”)
        if result.fidelity is None:
            print(f"  - ìœ íš¨ì„± ê²€ì‚¬: fidelityê°€ Noneì´ë¼ í—ˆìš©")
            result.fidelity = 0.0
        
        if result.entanglement is None:
            print(f"  - ìœ íš¨ì„± ê²€ì‚¬: entanglementê°€ Noneì´ë¼ í—ˆìš©")
            result.entanglement = 0.0
        
        # 2. Expressibility ë°ì´í„° ê²€ì¦ (ë„ˆë¬´ ì—„ê²©í•œ ê²€ì‚¬ ì™„í™”)
        if result.expressibility is None:
            # Noneì¸ ê²½ìš° ê¸°ë³¸ê°’ìœ¼ë¡œ ì´ˆê¸°í™”
            print(f"  - ìœ íš¨ì„± ê²€ì‚¬: expressibilityê°€ Noneì´ë¼ ê¸°ë³¸ê°’ìœ¼ë¡œ ì´ˆê¸°í™”")
            result.expressibility = {'kl_divergence': 0.5}  # ê¸°ë³¸ê°’ ì„¤ì •
        elif not isinstance(result.expressibility, dict):
            # dictê°€ ì•„ë‹Œ ê²½ìš° dictë¡œ ë³€í™˜
            print(f"  - ìœ íš¨ì„± ê²€ì‚¬: expressibilityê°€ dictê°€ ì•„ë‹ˆë¼ dictë¡œ ë³€í™˜")
            result.expressibility = {'kl_divergence': float(result.expressibility)}
        
        # 3. í”¼ë¸ë¦¬í‹° ê°’ ê²€ì¦ (ìŒìˆ˜ë‚˜ 1ë³´ë‹¤ í° ê°’ ì œê±°)
        if result.fidelity < 0 or result.fidelity > 1:
            return False
        
        if result.robust_fidelity is not None:
            if result.robust_fidelity < 0 or result.robust_fidelity > 1:
                return False
        
        # 4. ì–½í˜ë„ ê°’ ê²€ì¦ (ìŒìˆ˜ ì œê±°)
        if result.entanglement < 0:
            return False
        
        return True
    
    def merge_data(self, enable_filtering: bool = True) -> List[CircuitData]:
        """
        íšŒë¡œ ìŠ¤í™ê³¼ ì¸¡ì • ê²°ê³¼ë¥¼ circuit_idë¡œ ë³‘í•©í•˜ê³  ë°ì´í„° í’ˆì§ˆ ê²€ì¦
        
        Args:
            enable_filtering: Trueë©´ ë¬´íš¨í•œ ë°ì´í„° í•„í„°ë§, Falseë©´ ëª¨ë“  ë°ì´í„° í¬í•¨
            
        Returns:
            ë³‘í•©ëœ íšŒë¡œ ë°ì´í„° ë¦¬ìŠ¤íŠ¸
        """
        # ì¸¡ì • ê²°ê³¼ì™€ íšŒë¡œ ìŠ¤í™ íŒŒì‹±
        # ì‚¬ìš©í•  ë°ì´í„° íŒŒì¼ ê²½ë¡œ ê²°ì •
        if self.unified_data_path:
            data_file_path = str(self.unified_data_path)
        elif self.merged_results_path:
            data_file_path = str(self.merged_results_path)
        elif self.results_path:
            data_file_path = str(self.results_path)
        else:
            raise FileNotFoundError("ë°ì´í„° íŒŒì¼ ê²½ë¡œê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            
        measurement_results = self.load_measurement_results(data_file_path)
        circuit_specs = self.parse_circuit_specs()
        
        merged_data = []
        filtered_count = 0
        
        # circuit_idë¥¼ ê¸°ì¤€ìœ¼ë¡œ ë°ì´í„° ë³‘í•©
        for circuit_id in list(circuit_specs.keys()):
            # íšŒë¡œ ë°ì´í„° ìƒì„±
            circuit_data = CircuitData(
                circuit_spec=circuit_specs[circuit_id],
                measurement_result=measurement_results.get(circuit_id)
            )
            
            merged_data.append(circuit_data)
            
        # ì¸¡ì • ê²°ê³¼ë§Œ ìˆê³  íšŒë¡œ ìŠ¤í™ì´ ì—†ëŠ” ê²½ìš° ê²½ê³ 
        for circuit_id in measurement_results.keys():
            if circuit_id not in list(circuit_specs.keys()):
                print(f"Warning: íšŒë¡œ ìŠ¤í™ì´ ì—†ëŠ” ì¸¡ì • ê²°ê³¼ ID: {circuit_id}")
        
        if enable_filtering and filtered_count > 0:
            print(f"âœ… ë°ì´í„° í’ˆì§ˆ í•„í„°ë§ ì™„ë£Œ: {filtered_count}ê°œ ë¬´íš¨ ë°ì´í„° ì œê±°ë¨")
            print(f"ğŸ“Š ìœ íš¨í•œ ë°ì´í„°: {len(merged_data)}ê°œ / ì „ì²´: {len(merged_data) + filtered_count}ê°œ")
        
        self.circuit_data = merged_data
        return merged_data
    
    def split_dataset(
        self,
        train_ratio: float = 0.7,
        val_ratio: float = 0.15,
        test_ratio: float = 0.15,
        random_state: int = 42
    ) -> Tuple["QuantumCircuitDataset", "QuantumCircuitDataset", "QuantumCircuitDataset"]:
        """ë°ì´í„°ì…‹ ë¶„í• """
        if self.circuit_data is None:
            self.merge_data()
        
        # ë¹„ìœ¨ ê²€ì¦
        assert abs(train_ratio + val_ratio + test_ratio - 1.0) < 1e-6, "ë¹„ìœ¨ì˜ í•©ì´ 1ì´ ë˜ì–´ì•¼ í•©ë‹ˆë‹¤"
        
        # ë°ì´í„°ì…‹ í¬ê¸° í™•ì¸
        total_samples = len(self.circuit_data)
        print(f"Total samples in dataset: {total_samples}")
        
        if total_samples <= 3:
            print("Warning: Dataset is too small for proper splitting. Using all samples for all splits.")
            # ë°ì´í„°ì…‹ì´ ë„ˆë¬´ ì‘ì€ ê²½ìš°, ëª¨ë“  ë°ì´í„°ë¥¼ ëª¨ë“  ë¶„í• ì— ì‚¬ìš©
            return (
                QuantumCircuitDataset(self.circuit_data),
                QuantumCircuitDataset(self.circuit_data),
                QuantumCircuitDataset(self.circuit_data)
            )
        
        # ì²« ë²ˆì§¸ ë¶„í• : train + val vs test
        train_val_data, test_data = train_test_split(
            self.circuit_data,
            test_size=test_ratio,
            random_state=random_state
        )
        
        # ë‘ ë²ˆì§¸ ë¶„í• : train vs val
        adjusted_val_ratio = val_ratio / (train_ratio + val_ratio)
        train_data, val_data = train_test_split(
            train_val_data,
            test_size=adjusted_val_ratio,
            random_state=random_state
        )
        
        return (
            QuantumCircuitDataset(train_data),
            QuantumCircuitDataset(val_data), 
            QuantumCircuitDataset(test_data)
        )
    
    def get_dataset_stats(self) -> Dict[str, Any]:
        """ë°ì´í„°ì…‹ í†µê³„ ì •ë³´ ë°˜í™˜"""
        if self.circuit_data is None:
            self.merge_data()
        
        # ìœ íš¨í•œ measurement_resultê°€ ìˆëŠ” ë°ì´í„°ë§Œ í•„í„°ë§
        valid_data = [data for data in self.circuit_data if data.measurement_result is not None]
        
        num_circuits = len(self.circuit_data)
        num_valid_circuits = len(valid_data)
        
        # CircuitSpecì—ì„œ ê°€ì ¸ì˜¬ ìˆ˜ ìˆëŠ” ì •ë³´
        qubit_counts = [data.circuit_spec.num_qubits for data in self.circuit_data]
        gate_counts = [len(data.circuit_spec.gates) for data in self.circuit_data]
        
        stats = {
            "total_circuits": num_circuits,
            "valid_circuits": num_valid_circuits,
            "qubit_range": (min(qubit_counts), max(qubit_counts)),
            "avg_qubits": np.mean(qubit_counts),
            "gate_range": (min(gate_counts), max(gate_counts)),
            "avg_gates": np.mean(gate_counts)
        }
        
        if valid_data:
            # MeasurementResultì—ì„œ ê°€ì ¸ì˜¬ ìˆ˜ ìˆëŠ” ì •ë³´ (ìœ íš¨í•œ ë°ì´í„°ë§Œ)
            depths = [data.measurement_result.depth for data in valid_data]
            fidelities = [data.measurement_result.fidelity for data in valid_data]
            
            stats.update({
                "depth_range": (min(depths), max(depths)),
                "avg_depth": np.mean(depths),
                "fidelity_range": (min(fidelities), max(fidelities)),
                "avg_fidelity": np.mean(fidelities)
            })
            
            # ì¶”ê°€ ë©”íŠ¸ë¦­ í†µê³„ (ìˆëŠ” ê²½ìš°)
            entanglements = [data.measurement_result.entanglement for data in valid_data 
                           if data.measurement_result.entanglement is not None]
            if entanglements:
                stats["entanglement_range"] = (min(entanglements), max(entanglements))
                stats["avg_entanglement"] = np.mean(entanglements)
        
        return stats


def create_dataloaders(
    train_dataset: QuantumCircuitDataset,
    val_dataset: QuantumCircuitDataset,
    test_dataset: QuantumCircuitDataset,
    batch_size: int = 32,
    num_workers: int = 0,
    rtg_calculator = None,
    enable_rtg: bool = False
) -> Tuple[DataLoader, DataLoader, DataLoader]:
    """DataLoader ìƒì„± (RTG ì§€ì› í¬í•¨)"""
    
    # RTG í™œì„±í™” ì‹œ collate_fn ë³€ê²½
    if enable_rtg and rtg_calculator is not None:
        collate_fn = lambda batch: _rtg_collate_fn(batch, rtg_calculator)
    else:
        collate_fn = lambda batch: _standard_collate_fn(batch)  # í‘œì¤€ ë”•ì…”ë„ˆë¦¬ í˜•íƒœë¡œ ë°˜í™˜
    
    train_loader = DataLoader(
        train_dataset,
        batch_size=batch_size,
        shuffle=True,
        num_workers=num_workers,
        collate_fn=collate_fn
    )
    
    val_loader = DataLoader(
        val_dataset,
        batch_size=batch_size,
        shuffle=False,
        num_workers=num_workers,
        collate_fn=collate_fn
    )
    
    test_loader = DataLoader(
        test_dataset,
        batch_size=batch_size,
        shuffle=False,
        num_workers=num_workers,
        collate_fn=collate_fn
    )
    
    return train_loader, val_loader, test_loader


def _standard_collate_fn(batch):
    """í‘œì¤€ ë°°ì¹˜ ë°ì´í„° ìƒì„± (RTG ì—†ìŒ)"""
    import torch
    
    batch_size = len(batch)
    
    # ìµœëŒ€ ì‹œí€€ìŠ¤ ê¸¸ì´ ê³„ì‚°
    max_seq_len = max(len(spec.gates) for spec in batch)
    
    # ë°°ì¹˜ í…ì„œ ì´ˆê¸°í™”
    batch_states = torch.zeros(batch_size, max_seq_len, dtype=torch.long)
    batch_actions = torch.zeros(batch_size, max_seq_len, dtype=torch.long)
    batch_masks = torch.zeros(batch_size, max_seq_len, dtype=torch.bool)
    
    # ê° íšŒë¡œ ë°ì´í„°ë¥¼ ë°°ì¹˜ì— ì¶”ê°€ (ì¸ì½”ë”©ì€ ì„ë² ë”© íŒŒì´í”„ë¼ì¸ì—ì„œ ì²˜ë¦¬)
    for i, spec in enumerate(batch):
        seq_len = len(spec.gates)
        
        # ì‹¤ì œ ê²Œì´íŠ¸ íƒ€ì… ì¸ë±ìŠ¤ë¥¼ ì‚¬ìš©í•˜ì—¬ íƒ€ê²Ÿ ìƒì„±
        from quantumcommon.gates import QuantumGateRegistry
        gate_registry = QuantumGateRegistry()
        
        for j, gate in enumerate(spec.gates):
            batch_states[i, j] = j  # ì‹œê°„ ë‹¨ê³„
            # ì‹¤ì œ ê²Œì´íŠ¸ íƒ€ì… ì¸ë±ìŠ¤ ì‚¬ìš©
            gate_type_idx = gate_registry.get_gate_type(gate.name)
            batch_actions[i, j] = gate_type_idx
            batch_masks[i, j] = True
    
    # íƒ€ê²Ÿ ì†ì„± í…ì„œ ìƒì„±
    target_tensors = {}
    property_names = ['entanglement', 'fidelity', 'expressibility','robust_fidelity']
    
    for prop_name in property_names:
        prop_values = []
        for spec in batch:
            if hasattr(spec.measurement_result, prop_name):
                prop_val = getattr(spec.measurement_result, prop_name)
                # Handle dictionary values (e.g., expressibility)
                if isinstance(prop_val, dict):
                    if prop_name == 'expressibility':
                        prop_val = prop_val.get('kl_divergence', 0.0)
                    else:
                        prop_val = 0.0
                prop_values.append(float(prop_val) if prop_val is not None else 0.0)
            else:
                prop_values.append(0.0)
        prop_tensor = torch.tensor(prop_values, dtype=torch.float32)
        target_tensors[prop_name] = prop_tensor
    
    return {
        'input_sequence': batch_states,  # trainer.pyì—ì„œ ê¸°ëŒ€í•˜ëŠ” í‚¤ ì´ë¦„
        'states': batch_states,
        'actions': batch_actions,
        'attention_mask': batch_masks,
        'action_prediction_mask': batch_masks,
        'target_properties': target_tensors,
        'circuit_specs': batch
    }


def _rtg_collate_fn(batch, rtg_calculator):
    """RTG ê°’ì„ í¬í•¨í•œ ë°°ì¹˜ ë°ì´í„° ìƒì„±"""
    import torch
    
    batch_size = len(batch)
    
    # CircuitDataì—ì„œ í•„ìš”í•œ ì •ë³´ ì¶”ì¶œ
    circuit_specs = []
    states = []  # ìƒíƒœ ì‹œí€€ìŠ¤
    actions = []  # ì•¡ì…˜ ì‹œí€€ìŠ¤
    target_properties = {
        'entanglement': [],
        'fidelity': [],
        'expressibility': [],
        'robust_fidelity': []
    }
    
    max_seq_len = 0
    
    for circuit_data in batch:
        circuit_specs.append(circuit_data)
        
        # ê²Œì´íŠ¸ ì‹œí€€ìŠ¤ë¥¼ ìƒíƒœ-ì•¡ì…˜ ìŒìœ¼ë¡œ ë³€í™˜
        # Use proper embedding pipeline instead of random vectors
        from models.embedding_pipeline import EmbeddingPipeline
        
        embedding_config = {
            'gate_vocab_size': len(gate_registry.get_gate_vocab()),
            'max_qubits': circuit_data.num_qubits,
            'd_model': 256
        }
        
        embedding_pipeline = EmbeddingPipeline(embedding_config)
        circuit_embeddings = embedding_pipeline.embed_circuit({
            'gates': circuit_data.gates,
            'num_qubits': circuit_data.num_qubits,
            'depth': len(circuit_data.gates)
        })
        
        gate_sequence = circuit_embeddings['gate_embeddings']
        
        if gate_sequence:
            states.append(torch.stack(gate_sequence))
            actions.append(torch.stack(gate_sequence))  # ì•¡ì…˜ë„ ë™ì¼í•˜ê²Œ ì„¤ì •
            max_seq_len = max(max_seq_len, len(gate_sequence))
        else:
            # ë¹ˆ ì‹œí€€ìŠ¤ ì²˜ë¦¬
            empty_seq = torch.zeros(1, 256)
            states.append(empty_seq)
            actions.append(empty_seq)
            max_seq_len = max(max_seq_len, 1)
        
        # ì •ë‹µ ì†ì„±ê°’ ì¶”ì¶œ
        if circuit_data.measurement_result:
            target_properties['entanglement'].append(
                circuit_data.measurement_result.entanglement or 0.0
            )
            target_properties['fidelity'].append(
                circuit_data.measurement_result.fidelity or 0.0
            )
            
            # Expressibility ì²˜ë¦¬ (ë”•ì…”ë„ˆë¦¬ì¸ ê²½ìš° KL divergence ì¶”ì¶œ)
            expressibility_val = getattr(circuit_data.measurement_result, 'expressibility', 0.0)
            if isinstance(expressibility_val, dict):
                expressibility_val = expressibility_val.get('kl_divergence', 0.0)
            target_properties['expressibility'].append(float(expressibility_val))
            
            # Robust fidelity ì¶”ì¶œ
            robust_fidelity_val = getattr(circuit_data.measurement_result, 'robust_fidelity', 0.0)
            target_properties['robust_fidelity'].append(float(robust_fidelity_val or 0.0))
        else:
            # ê¸°ë³¸ê°’ ì‚¬ìš©
            target_properties['entanglement'].append(0.0)
            target_properties['fidelity'].append(0.0)
            target_properties['expressibility'].append(0.0)
            target_properties['robust_fidelity'].append(0.0)
    
    # ì‹œí€€ìŠ¤ ê¸¸ì´ íŒ¨ë”©
    padded_states = []
    padded_actions = []
    attention_masks = []
    
    for i in range(batch_size):
        seq_len = states[i].shape[0]
        
        # íŒ¨ë”© ì²˜ë¦¬
        if seq_len < max_seq_len:
            pad_len = max_seq_len - seq_len
            padded_state = torch.cat([
                states[i],
                torch.zeros(pad_len, 256)
            ], dim=0)
            padded_action = torch.zeros(max_seq_len, dtype=torch.long)
            gate_vocab = gate_registry.get_gate_vocab()
            for j, gate in enumerate(circuit_specs[i].gates):
                gate_idx = gate_vocab.get(gate.name.lower(), 0)  # ì‹¤ì œ ê²Œì´íŠ¸ ì¸ë±ìŠ¤
                padded_action[j] = gate_idx
            mask = torch.cat([
                torch.ones(seq_len, dtype=torch.bool),
                torch.zeros(pad_len, dtype=torch.bool)
            ])
        else:
            padded_state = states[i]
            padded_action = torch.zeros(max_seq_len, dtype=torch.long)
            gate_vocab = gate_registry.get_gate_vocab()
            for j, gate in enumerate(circuit_specs[i].gates):
                gate_idx = gate_vocab.get(gate.name.lower(), 0)  # ê¸°ë³¸ê°’ 0 (ì²« ë²ˆì§¸ ê²Œì´íŠ¸)
                padded_action[j] = gate_idx
            mask = torch.ones(seq_len, dtype=torch.bool)
        
        padded_states.append(padded_state)
        padded_actions.append(padded_action)
        attention_masks.append(mask)
    
    # ë°°ì¹˜ í…ì„œë¡œ ë³€í™˜
    batch_states = torch.stack(padded_states)  # [batch_size, seq_len, d_model]
    batch_actions = torch.stack(padded_actions)  # [batch_size, seq_len, d_model]
    batch_masks = torch.stack(attention_masks)  # [batch_size, seq_len]
    
    # ëª©í‘œ ì†ì„±ê°’ì„ í…ì„œë¡œ ë³€í™˜
    target_tensors = {}
    for prop_name, prop_values in target_properties.items():
        # ê° ì‹œí€€ìŠ¤ì˜ ëª¨ë“  ìŠ¤í…ì— ëŒ€í•´ ë™ì¼í•œ ëª©í‘œê°’ ì‚¬ìš©
        prop_tensor = torch.zeros(batch_size, max_seq_len)
        for i, prop_val in enumerate(prop_values):
            prop_tensor[i, :] = prop_val
        target_tensors[prop_name] = prop_tensor
    
    # RTG ê³„ì‚° (ì‹¤ì œ RTG Calculator ì‚¬ìš©)
    if rtg_calculator is not None:
        try:
            # Property ëª¨ë¸ë¡œ ì˜ˆì¸¡
            predicted_properties = rtg_calculator.calculate_sequence_properties(
                batch_states, batch_masks
            )
            
            # í‘œì¤€ RL RTG ê³„ì‚°
            rtg_rewards = rtg_calculator.calculate_rtg_rewards(
                predicted_properties, target_tensors, batch_masks, gamma=0.99
            )
        except Exception as e:
            print(f"âš ï¸ RTG ê³„ì‚° ì˜¤ë¥˜: {e}")
            # í´ë°±: ê¸°ë³¸ê°’ ì‚¬ìš©
            rtg_rewards = torch.ones(batch_size, max_seq_len) * 0.5
    else:
        # RTG Calculatorê°€ ì—†ìœ¼ë©´ ê¸°ë³¸ê°’
        rtg_rewards = torch.ones(batch_size, max_seq_len) * 0.5
    
    # ğŸ”¥ ROOT CAUSE FIX: Generate target_qubits from circuit data
    batch_target_qubits = []
    batch_target_params = []
    
    for i, circuit_data in enumerate(circuit_specs):
        # Extract qubit and parameter information from gates
        gate_qubits = []
        gate_params = []
        
        for gate in circuit_data.gates:
            # Extract qubit positions (pad to 2 qubits for consistency)
            if hasattr(gate, 'qubits') and gate.qubits:
                qubits = gate.qubits[:2]  # Take first 2 qubits
                if len(qubits) == 1:
                    qubits.append(-1)  # Pad single-qubit gates
                gate_qubits.append(qubits)
            else:
                gate_qubits.append([0, -1])  # Default: qubit 0, no second qubit
            
            # Extract parameter values
            if hasattr(gate, 'parameters') and gate.parameters:
                gate_params.append(float(gate.parameters[0]))
            else:
                gate_params.append(0.0)  # Default parameter
        
        # Pad sequences to max_seq_len
        while len(gate_qubits) < max_seq_len:
            gate_qubits.append([-1, -1])  # Padding qubits
            gate_params.append(0.0)  # Padding parameters
        
        batch_target_qubits.append(torch.tensor(gate_qubits[:max_seq_len], dtype=torch.long))
        batch_target_params.append(torch.tensor(gate_params[:max_seq_len], dtype=torch.float))
    
    return {
        'input_sequence': batch_states,  # trainer.pyì—ì„œ ê¸°ëŒ€í•˜ëŠ” í‚¤ ì´ë¦„
        'states': batch_states,
        'target_actions': batch_actions,
        'target_qubits': torch.stack(batch_target_qubits),  # ğŸ”¥ FIX: Add missing target_qubits
        'target_params': torch.stack(batch_target_params),  # ğŸ”¥ FIX: Add missing target_params
        'rtg': rtg_rewards,
        'attention_mask': batch_masks,
        'action_prediction_mask': batch_masks,
        'target_properties': target_tensors,
        'circuit_specs': circuit_specs
    }


# ì‚¬ìš© ì˜ˆì‹œ
if __name__ == "__main__":
    # ë°©ë²• 1: í†µí•© ë°ì´í„° íŒŒì¼ë¡œ ë¡œë”© (ê¶Œì¥)
    manager = DatasetManager(
        unified_data_path=r"C:\Users\jungh\Documents\GitHub\Kaist\OAT_Model\raw_data\merged_data.json"
    )
    
    # ë°©ë²• 2: ê°œë³„ íŒŒì¼ë¡œ ë¡œë”© (ë ˆê±°ì‹œ ì§€ì›)
    # manager = DatasetManager(
    #     results_path="path/to/results.json",
    #     circuits_path="path/to/circuits.json"
    # )
    
    # ë°©ë²• 3: ë³‘í•©ëœ ê²°ê³¼ íŒŒì¼ë¡œ ë¡œë”© (ë ˆê±°ì‹œ ì§€ì›)
    # manager = DatasetManager(
    #     merged_results_path="path/to/merged_results.json",
    #     circuits_path="path/to/circuits.json"
    # )
    
    # ë°ì´í„° ë³‘í•© (ê¸°ë³¸ì ìœ¼ë¡œ í’ˆì§ˆ í•„í„°ë§ í™œì„±í™”)
    circuit_data = manager.merge_data(enable_filtering=True)
    print(f"ì´ {len(circuit_data)}ê°œì˜ ìœ íš¨í•œ íšŒë¡œ ë°ì´í„° ë¡œë”© ì™„ë£Œ")
    print(f"í†µí•© ë°ì´í„° íŒŒì¼ ì‚¬ìš©: {manager.unified_data_path is not None}")
    
    # í†µê³„ ì •ë³´ ì¶œë ¥
    stats = manager.get_dataset_stats()
    print("\në°ì´í„°ì…‹ í†µê³„:")
    for key, value in stats.items():
        print(f"  {key}: {value}")
    
    # ë°ì´í„°ì…‹ ë¶„í• 
    train_dataset, val_dataset, test_dataset = manager.split_dataset()
    print(f"\në°ì´í„°ì…‹ ë¶„í•  ì™„ë£Œ:")
    print(f"  Train: {len(train_dataset)}")
    print(f"  Validation: {len(val_dataset)}")
    print(f"  Test: {len(test_dataset)}")
    
    # ì²« ë²ˆì§¸ ë°ì´í„° ìƒ˜í”Œ í™•ì¸
    if len(train_dataset) > 0:
        sample = train_dataset[0]
        print(f"\nì²« ë²ˆì§¸ ìƒ˜í”Œ:")
        print(f"  Circuit ID: {sample.circuit_id}")
        print(f"  Qubits: {sample.num_qubits}")
        print(f"  Gates: {len(sample.gates)}")
        print(f"  Fidelity: {sample.measurement_result.fidelity}")
        print(f"  Entanglement: {sample.measurement_result.entanglement}")

